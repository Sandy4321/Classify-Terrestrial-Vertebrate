{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservation Internaitonal's TEAM has labeled camera trap images of terrestial mammals\n",
    "\n",
    "- Images require manual classification from experts in the field\n",
    "- Many of the images are misclassified\n",
    "- There is a class of unlabeled images\n",
    "- There is a class of unknown images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wildlife Image Classification Literature Review\n",
    "1. SVM Models\n",
    "2. Learning Models (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Visual Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "- Manual Cropping\n",
    "- Image Segmentation with Graph Cut \n",
    "http://cmp.felk.cvut.cz/~smidm/python-packages-for-graph-cuts-on-images.html\n",
    "- Scale Invariant Feature Transform (SIFT)\n",
    "- Cell-structured Local Binary Pattern (cLBP) descriptor\n",
    "- Fisher Vector Coding\n",
    "- Spatial Pyramid Strategy\n",
    "- Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEAM Terrestial Species Images Limitations\n",
    "- Highly unbalanced classes of species\n",
    "- Manually classified by experts in the field\n",
    "- Context matters: busrts of images are understood by experts as a sequence of images containing the identified species (part of animal species v whole animal species in frame problem)\n",
    "- Classification contain errors\n",
    "- Existence of endangered species images preclude the use of citizen scientists to help classify images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "ROWS = 180  #720\n",
    "COLS = 320 #1280\n",
    "CHANNELS = 3\n",
    "SPECIES_CLASSES = ['Loxodonta']\n",
    "DIRECTORY = \"/Users/Luxive/OneDrive/Machine_Learning/Harvard/Final_Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"OpenCV version\",cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "filename = \"/Users/Luxive/Dropbox/TEAM_Machine Learning/Loxodonta/TEAM-DataPackage-20161115123529_3242/Terrestrial Vertebrate/NNN/2014.01/CT-NNN-1/CT-NNN-1-17/100-IMG_4191.JPG\"\n",
    "Image(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols= 850, 1200\n",
    "im_array = cv2.imread(filename,0)\n",
    "template = np.zeros([ img_rows, img_cols], dtype='uint8') # initialisation of the template\n",
    "template[:, :] = im_array[50:900,0:1200] # I try multiple times to find the correct rectangle. \n",
    "#template /= 255.\n",
    "plt.subplots(figsize=(10, 7))\n",
    "plt.subplot(121),plt.imshow(template, cmap='gray') \n",
    "plt.subplot(122), plt.imshow(im_array, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(filename,0) \n",
    "img2 = img\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for meth in methods:\n",
    "    img = img2\n",
    "    method = eval(meth)\n",
    " \n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "    cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray') #,aspect='auto'\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_images(species):\n",
    "    \"\"\"Load files from directory folder\"\"\"\n",
    "    \"\"\"Use os.walk() traversal method\"\"\"\n",
    "    images = []\n",
    "    for root, dirs, files in os.walk(DIRECTORY+species):\n",
    "        for file in files:\n",
    "            if file.endswith(\".JPG\"):\n",
    "                images.append(file)\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "    return im\n",
    "\n",
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for species in SPECIES_CLASSES:\n",
    "    species_files = get_images(species)\n",
    "    files.extend(species_files)\n",
    "\n",
    "    y_species = np.tile(species, len(species_files))\n",
    "    y_all.extend(y_species)\n",
    "    print(\"{0} photos of {1}\".format(len(species_files), species))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(DIRECTORY+species+'/'+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check out a species from each class\n",
    "uniq = np.unique(y_all, return_index=True)\n",
    "for f, i in zip(uniq[0], uniq[1]):\n",
    "    plt.imshow(X_all[i])\n",
    "    plt.title(f)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "y_all = np_utils.to_categorical(y_all)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'sparse_categorical_crossentropy'\n",
    "\n",
    "def center_normalize(x):\n",
    "    return (x - K.mean(x)) / K.std(x)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(SPECIES_CLASSES)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=objective, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
    "        \n",
    "model.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n",
    "              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bb_metadata = pd.read_csv(\"data/TV-20161130134129_5302.csv\", header=46,low_memory=False)\n",
    "nnn_metadata = pd.read_csv(\"/Users/Luxive/Dropbox/TEAM_Machine Learning/Loxodonta/TEAM-DataPackage-20161205130624_1284/Terrestrial Vertebrate/TV-20161205130624_1284.csv\", header=46,low_memory=False)\n",
    "# vr_metadata = pd.read_csv(\"data/TV-20161204185054_1706.csv\", header=46,low_memory=False)\n",
    "# udz_metadata = pd.read_csv(\"data/TV-20161204185203_1536.csv\", header=46,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_metadata = pd.concat([bb_metadata, nnn_metadata, vr_metadata, udz_metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnn_metadata['Species'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/Luxive/Dropbox/TEAM_Machine Learning/\"\n",
    "\n",
    "def count_images(species):\n",
    "    \"\"\"Load files from directory folder\"\"\"\n",
    "    \"\"\"Use os.walk() traversal method\"\"\"\n",
    "    i = 0\n",
    "    for root, dirs, files in os.walk(directory+species):\n",
    "        for file in files:\n",
    "            if file.endswith(\".JPG\"):\n",
    "                i += 1\n",
    "    return i\n",
    "\n",
    "actual_images = count_images(species)\n",
    "print(actual_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# expected versus actual images\n",
    "series = pd.Series({\"ExpectedImages\": nnn_metadata['Species'].count(), \"ActualImages\": actual_images})\n",
    "image_check = pd.DataFrame([series])\n",
    "image_check['Difference'] = image_check['ExpectedImages'] - image_check['ActualImages']\n",
    "image_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of null values and data types per column\n",
    "# You can use DataFrame.info() as well\n",
    "null_df = pd.DataFrame({'number of null values': nnn_metadata.isnull().sum(),\n",
    "                        'data type' : nnn_metadata.dtypes,\n",
    "                        'count': nnn_metadata.count()})\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import HTML\n",
    "# def css_styling():\n",
    "#     styles = open('css/custom.css', 'r').read()\n",
    "#     return HTML(\"<style>\"+styles+\"</style>\")\n",
    "# css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
